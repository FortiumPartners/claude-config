#!/usr/bin/env python3
"""
Docker Configuration Generator
Production-ready Docker configurations with security best practices
Part of Infrastructure Management Subagent v1.0
"""

import os
import sys
import json
import yaml
import argparse
import subprocess
from typing import Dict, Any, List, Optional
from pathlib import Path
import re
import tempfile
from datetime import datetime

class DockerConfigGenerator:
    """
    Advanced Docker configuration generation with security hardening,
    multi-stage optimization, and development workflow support.
    """
    
    def __init__(self, template_dir: str = None):
        self.template_dir = Path(template_dir) if template_dir else Path(__file__).parent
        self.templates = {
            'dockerfile': 'multi-stage-template.Dockerfile',
            'compose': 'docker-compose-template.yml',
            'dockerignore': '.dockerignore-template',
            'healthcheck': 'healthcheck-template.sh'
        }
        
    def generate_dockerfile(self, config: Dict[str, Any], output_file: str = None) -> str:
        """
        Generate optimized multi-stage Dockerfile from template and configuration.
        
        Args:
            config: Configuration variables for template rendering
            output_file: Optional output file path
            
        Returns:
            Generated Dockerfile as string
        """
        
        # Apply security defaults and optimizations
        config = self._apply_docker_defaults(config)
        
        # Validate configuration
        self._validate_docker_config(config)
        
        # Load template
        template_path = self.template_dir / self.templates['dockerfile']
        with open(template_path, 'r') as f:
            template_content = f.read()
            
        # Render template
        rendered_dockerfile = self._render_template(template_content, config)
        
        # Optimize Dockerfile
        rendered_dockerfile = self._optimize_dockerfile(rendered_dockerfile, config)
        
        # Validate generated Dockerfile
        validation_result = self._validate_dockerfile(rendered_dockerfile)
        
        if not validation_result['valid']:
            print("âš ï¸  Dockerfile validation warnings:")
            for warning in validation_result['warnings']:
                print(f"   - {warning}")
                
        # Save to file if specified
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w') as f:
                f.write(rendered_dockerfile)
                
            print(f"âœ… Generated Dockerfile: {output_path}")
            
        return rendered_dockerfile
        
    def generate_compose_file(self, config: Dict[str, Any], output_file: str = None) -> str:
        """
        Generate Docker Compose file with development and production configurations.
        
        Args:
            config: Configuration variables for template rendering
            output_file: Optional output file path
            
        Returns:
            Generated docker-compose.yml as string
        """
        
        # Apply compose defaults
        config = self._apply_compose_defaults(config)
        
        # Load template
        template_path = self.template_dir / self.templates['compose']
        with open(template_path, 'r') as f:
            template_content = f.read()
            
        # Render template
        rendered_compose = self._render_template(template_content, config)
        
        # Validate YAML structure
        try:
            yaml.safe_load(rendered_compose)
        except yaml.YAMLError as e:
            raise ValueError(f"Generated docker-compose.yml has invalid YAML: {str(e)}")
            
        # Save to file if specified
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w') as f:
                f.write(rendered_compose)
                
            print(f"âœ… Generated docker-compose.yml: {output_path}")
            
        return rendered_compose
        
    def generate_dockerignore(self, config: Dict[str, Any], output_file: str = None) -> str:
        """
        Generate optimized .dockerignore file to reduce build context size.
        
        Args:
            config: Configuration for dockerignore patterns
            output_file: Optional output file path
            
        Returns:
            Generated .dockerignore content
        """
        
        # Default ignore patterns
        ignore_patterns = [
            "# Generated by Infrastructure Management Subagent",
            "# Node.js",
            "node_modules/",
            "npm-debug.log*",
            "yarn-debug.log*",
            "yarn-error.log*",
            ".npm",
            ".yarn-integrity",
            "",
            "# Build outputs",
            "dist/",
            "build/",
            "out/",
            "",
            "# Development files",
            "*.md",
            ".git/",
            ".gitignore",
            ".gitattributes",
            ".vscode/",
            ".idea/",
            "*.swp",
            "*.swo",
            "*~",
            "",
            "# Testing",
            "coverage/",
            ".nyc_output/",
            "test/",
            "tests/",
            "**/*.test.*",
            "**/*.spec.*",
            "",
            "# Environment files",
            ".env*",
            "!.env.example",
            "",
            "# Logs",
            "logs/",
            "*.log",
            "",
            "# OS generated files",
            ".DS_Store",
            ".DS_Store?",
            "._*",
            ".Spotlight-V100",
            ".Trashes",
            "ehthumbs.db",
            "Thumbs.db",
            "",
            "# Docker",
            "Dockerfile*",
            "docker-compose*",
            ".dockerignore",
            "",
            "# CI/CD",
            ".github/",
            ".gitlab-ci.yml",
            "Jenkinsfile",
            "",
            "# Documentation",
            "docs/",
            "README*",
            "CHANGELOG*",
            "LICENSE*",
        ]
        
        # Add custom patterns
        if config.get('ADDITIONAL_IGNORE_PATTERNS'):
            ignore_patterns.extend([
                "",
                "# Custom patterns"
            ])
            ignore_patterns.extend(config['ADDITIONAL_IGNORE_PATTERNS'])
            
        # Add language-specific patterns
        package_manager = config.get('PACKAGE_MANAGER', '')
        
        if package_manager == 'pip':
            ignore_patterns.extend([
                "",
                "# Python",
                "__pycache__/",
                "*.py[cod]",
                "*$py.class",
                "*.so",
                ".Python",
                "build/",
                "develop-eggs/",
                "dist/",
                "downloads/",
                "eggs/",
                ".eggs/",
                "lib/",
                "lib64/",
                "parts/",
                "sdist/",
                "var/",
                "wheels/",
                "*.egg-info/",
                ".installed.cfg",
                "*.egg",
                "venv/",
                "env/",
                ".venv/",
                ".env/",
            ])
        elif package_manager == 'go':
            ignore_patterns.extend([
                "",
                "# Go",
                "vendor/",
                "*.exe",
                "*.exe~",
                "*.dll",
                "*.so",
                "*.dylib",
                "*.test",
                "*.out",
            ])
            
        dockerignore_content = '\n'.join(ignore_patterns)
        
        # Save to file if specified
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w') as f:
                f.write(dockerignore_content)
                
            print(f"âœ… Generated .dockerignore: {output_path}")
            
        return dockerignore_content
        
    def generate_container_configs(self, config: Dict[str, Any], output_dir: str = None) -> Dict[str, str]:
        """
        Generate complete Docker container configuration including Dockerfile,
        docker-compose.yml, .dockerignore, and helper scripts.
        
        Args:
            config: Application configuration
            output_dir: Directory to save generated files
            
        Returns:
            Dictionary mapping file types to generated content
        """
        
        app_name = config.get('APP_NAME', 'my-app')
        output_dir = Path(output_dir) if output_dir else Path(f"./{app_name}-docker")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        configs = {}
        
        # Generate Dockerfile
        dockerfile_path = output_dir / "Dockerfile"
        dockerfile_content = self.generate_dockerfile(config, str(dockerfile_path))
        configs['dockerfile'] = dockerfile_content
        
        # Generate docker-compose.yml
        compose_path = output_dir / "docker-compose.yml"
        compose_content = self.generate_compose_file(config, str(compose_path))
        configs['compose'] = compose_content
        
        # Generate .dockerignore
        dockerignore_path = output_dir / ".dockerignore"
        dockerignore_content = self.generate_dockerignore(config, str(dockerignore_path))
        configs['dockerignore'] = dockerignore_content
        
        # Generate helper scripts
        self._generate_docker_scripts(config, output_dir)
        
        # Generate development docker-compose override
        dev_config = {**config, 'NODE_ENV': 'development', 'BUILD_TARGET': 'development'}
        dev_compose_path = output_dir / "docker-compose.override.yml"
        dev_compose_content = self._generate_dev_compose_override(dev_config)
        
        with open(dev_compose_path, 'w') as f:
            f.write(dev_compose_content)
        configs['dev_compose'] = dev_compose_content
        
        # Generate production docker-compose
        prod_config = {**config, 'NODE_ENV': 'production', 'BUILD_TARGET': 'production'}
        prod_compose_path = output_dir / "docker-compose.prod.yml"
        prod_compose_content = self.generate_compose_file(prod_config)
        
        with open(prod_compose_path, 'w') as f:
            f.write(prod_compose_content)
        configs['prod_compose'] = prod_compose_content
        
        print(f"\nâœ… Generated {len(configs)} Docker configuration files in {output_dir}")
        print(f"ðŸ“ Build script: {output_dir}/build.sh")
        print(f"ðŸš€ Deploy script: {output_dir}/deploy.sh")
        print(f"ðŸ” Security scan script: {output_dir}/security-scan.sh")
        
        return configs
        
    def _apply_docker_defaults(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply Docker security defaults and best practices."""
        
        defaults = {
            'BASE_BUILD_IMAGE': 'node:18-alpine',
            'RUNTIME_IMAGE': 'gcr.io/distroless/nodejs18-debian11',
            'WORKDIR': '/app',
            'USER_ID': 1001,
            'GROUP_ID': 3000,
            'USER_NAME': 'appuser',
            'GROUP_NAME': 'appgroup',
            'PORT': 8080,
            'NODE_ENV': 'production',
            'READ_ONLY_ROOTFS': True,
            'HEALTH_CHECK_ENABLED': True,
            'HEALTH_CHECK_CMD': 'curl -f http://localhost:$PORT/health || exit 1',
            'ENABLE_SECURITY_SCAN': True,
            'TRIVY_EXIT_CODE': 1,
            'TRIVY_SEVERITY': 'HIGH,CRITICAL',
            'BUILD_DATE': datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'VERSION': '1.0.0',
            'LICENSE': 'MIT'
        }
        
        # Package manager specific defaults
        if config.get('PACKAGE_MANAGER') == 'npm':
            defaults.update({
                'PACKAGE_FILES': [
                    {'src': 'package*.json', 'dest': './'}
                ]
            })
        elif config.get('PACKAGE_MANAGER') == 'yarn':
            defaults.update({
                'PACKAGE_FILES': [
                    {'src': 'package.json', 'dest': './'},
                    {'src': 'yarn.lock', 'dest': './'}
                ]
            })
        elif config.get('PACKAGE_MANAGER') == 'pip':
            defaults.update({
                'BASE_BUILD_IMAGE': 'python:3.11-alpine',
                'RUNTIME_IMAGE': 'gcr.io/distroless/python3-debian11',
                'PACKAGE_FILES': [
                    {'src': 'requirements.txt', 'dest': './'}
                ]
            })
        elif config.get('PACKAGE_MANAGER') == 'go':
            defaults.update({
                'BASE_BUILD_IMAGE': 'golang:1.20-alpine',
                'RUNTIME_IMAGE': 'gcr.io/distroless/static-debian11',
                'PACKAGE_FILES': [
                    {'src': 'go.mod', 'dest': './'},
                    {'src': 'go.sum', 'dest': './'}
                ]
            })
            
        return {**defaults, **config}
        
    def _apply_compose_defaults(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply Docker Compose defaults and best practices."""
        
        defaults = {
            'RESTART_POLICY': 'unless-stopped',
            'NETWORK_NAME': 'app-network',
            'SUBNET': '172.20.0.0/16',
            'READ_ONLY_CONTAINER': True,
            'CPU_LIMIT': '1.0',
            'MEMORY_LIMIT': '512M',
            'CPU_RESERVATION': '0.25',
            'MEMORY_RESERVATION': '128M',
            'LOG_DRIVER': 'json-file',
            'LOG_MAX_SIZE': '10m',
            'LOG_MAX_FILES': '3',
            'HEALTH_CHECK_INTERVAL': '30s',
            'HEALTH_CHECK_TIMEOUT': '10s',
            'HEALTH_CHECK_RETRIES': 3,
            'HEALTH_CHECK_START_PERIOD': '40s',
            'ENABLE_METRICS': True,
            'LOG_LEVEL': 'info'
        }
        
        return {**defaults, **config}
        
    def _validate_docker_config(self, config: Dict[str, Any]):
        """Validate Docker configuration for security and best practices."""
        
        warnings = []
        
        # Check for root user
        if config.get('USER_ID') == 0:
            warnings.append("Container should not run as root user (USER_ID: 0)")
            
        # Check for privileged mode
        if config.get('PRIVILEGED', False):
            warnings.append("Privileged mode should be avoided")
            
        # Check for host network
        if config.get('NETWORK_MODE') == 'host':
            warnings.append("Host network mode reduces isolation")
            
        # Check for exposed ports
        if config.get('PORT', 8080) < 1024 and config.get('USER_ID', 1001) != 0:
            warnings.append(f"Port {config['PORT']} requires root privileges")
            
        if warnings:
            print("Docker configuration warnings:")
            for warning in warnings:
                print(f"  âš ï¸  {warning}")
                
    def _optimize_dockerfile(self, dockerfile: str, config: Dict[str, Any]) -> str:
        """Optimize Dockerfile for size and security."""
        
        lines = dockerfile.split('\n')
        optimized_lines = []
        
        for line in lines:
            # Remove empty lines and comments in production
            if config.get('NODE_ENV') == 'production' and (
                line.strip() == '' or line.strip().startswith('#')
            ):
                continue
                
            # Combine RUN commands where possible
            if line.strip().startswith('RUN ') and optimized_lines and optimized_lines[-1].strip().startswith('RUN '):
                # Combine with previous RUN command
                optimized_lines[-1] = optimized_lines[-1].rstrip(' \\') + ' && \\\n    ' + line.strip()[4:]
            else:
                optimized_lines.append(line)
                
        return '\n'.join(optimized_lines)
        
    def _validate_dockerfile(self, dockerfile: str) -> Dict[str, Any]:
        """Validate Dockerfile for best practices."""
        
        validation_result = {
            'valid': True,
            'warnings': [],
            'errors': []
        }
        
        lines = dockerfile.split('\n')
        
        # Check for best practices
        has_user = False
        has_healthcheck = False
        has_label = False
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('USER '):
                has_user = True
                
            if line.startswith('HEALTHCHECK'):
                has_healthcheck = True
                
            if line.startswith('LABEL'):
                has_label = True
                
            # Check for security issues
            if 'ADD http' in line or 'ADD https' in line:
                validation_result['warnings'].append("Consider using COPY instead of ADD for URLs")
                
            if 'chmod 777' in line or 'chmod 666' in line:
                validation_result['warnings'].append("Avoid overly permissive file permissions")
                
        if not has_user:
            validation_result['warnings'].append("Consider adding USER instruction for security")
            
        if not has_healthcheck:
            validation_result['warnings'].append("Consider adding HEALTHCHECK instruction")
            
        if not has_label:
            validation_result['warnings'].append("Consider adding metadata LABELs")
            
        validation_result['valid'] = len(validation_result['errors']) == 0
        
        return validation_result
        
    def _render_template(self, template: str, config: Dict[str, Any]) -> str:
        """Simple Jinja2-like template rendering."""
        
        # Variable substitution
        def replace_var(match):
            var_expr = match.group(1).strip()
            
            if '|' in var_expr:
                var_name, default_expr = var_expr.split('|', 1)
                var_name = var_name.strip()
                default_match = re.search(r'default\(["\']?([^"\']*)["\']?\)', default_expr)
                default_value = default_match.group(1) if default_match else ''
                return str(config.get(var_name, default_value))
            else:
                return str(config.get(var_expr, ''))
                
        template = re.sub(r'\{\{\s*([^}]+)\s*\}\}', replace_var, template)
        
        # Process conditionals and loops (simplified)
        lines = template.split('\n')
        result_lines = []
        skip_level = 0
        
        for line in lines:
            # Handle if statements
            if_match = re.search(r'\{\%\s*if\s+(\w+)\s*\%\}', line)
            if if_match:
                condition = if_match.group(1)
                if not config.get(condition):
                    skip_level += 1
                continue
                
            # Handle endif
            if re.search(r'\{\%\s*endif\s*\%\}', line):
                if skip_level > 0:
                    skip_level -= 1
                continue
                
            # Handle for loops (basic)
            for_match = re.search(r'\{\%\s*for\s+(\w+)\s+in\s+(\w+)\s*\%\}', line)
            if for_match:
                loop_var = for_match.group(1)
                list_var = for_match.group(2)
                items = config.get(list_var, [])
                
                # Find endfor
                loop_lines = []
                i = lines.index(line) + 1
                while i < len(lines) and not re.search(r'\{\%\s*endfor\s*\%\}', lines[i]):
                    loop_lines.append(lines[i])
                    i += 1
                    
                # Process loop items
                for item in items:
                    for loop_line in loop_lines:
                        processed_line = loop_line.replace(f'{{{{{ loop_var }}}}}', str(item))
                        if isinstance(item, dict):
                            for key, value in item.items():
                                processed_line = processed_line.replace(f'{{{{{ loop_var }.{key} }}}}', str(value))
                        if skip_level == 0:
                            result_lines.append(processed_line)
                            
                continue
                
            if re.search(r'\{\%\s*endfor\s*\%\}', line):
                continue
                
            if skip_level == 0:
                result_lines.append(line)
                
        return '\n'.join(result_lines)
        
    def _generate_dev_compose_override(self, config: Dict[str, Any]) -> str:
        """Generate development docker-compose override file."""
        
        override_content = f"""# Development Docker Compose Override
# Generated by Infrastructure Management Subagent v1.0

version: '3.8'

services:
  {config.get('APP_NAME', 'app')}:
    build:
      target: development
    environment:
      NODE_ENV: development
      DEBUG: "true"
    volumes:
      - ./src:/app/src:cached
      - ./config:/app/config:ro
      - /app/node_modules
    ports:
      - "{config.get('DEBUG_HOST_PORT', 9229)}:{config.get('DEBUG_PORT', 9229)}"
    command: npm run dev
"""
        return override_content
        
    def _generate_docker_scripts(self, config: Dict[str, Any], output_dir: Path):
        """Generate helper scripts for Docker operations."""
        
        app_name = config.get('APP_NAME', 'my-app')
        
        # Build script
        build_script = f"""#!/bin/bash
# Docker build script for {app_name}
# Generated by Infrastructure Management Subagent

set -euo pipefail

# Colors
RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
NC='\\033[0m'

log_info() {{ echo -e "${{GREEN}}[INFO]${{NC}} $1"; }}
log_warn() {{ echo -e "${{YELLOW}}[WARN]${{NC}} $1"; }}
log_error() {{ echo -e "${{RED}}[ERROR]${{NC}} $1"; }}

# Configuration
IMAGE_NAME="{config.get('IMAGE_NAME', app_name)}"
VERSION="${{1:-latest}}"
BUILD_TARGET="${{2:-production}}"

log_info "Building Docker image: $IMAGE_NAME:$VERSION"

# Build with security scanning
docker build \\
    --target "$BUILD_TARGET" \\
    --tag "$IMAGE_NAME:$VERSION" \\
    --tag "$IMAGE_NAME:latest" \\
    --build-arg BUILD_DATE="$(date -u +'%Y-%m-%dT%H:%M:%SZ')" \\
    --build-arg VERSION="$VERSION" \\
    .

if [ $? -eq 0 ]; then
    log_info "Build completed successfully"
    
    # Display image information
    docker images "$IMAGE_NAME:$VERSION"
    
    # Security scan with Trivy (if available)
    if command -v trivy &> /dev/null; then
        log_info "Running security scan..."
        trivy image --exit-code 0 --severity HIGH,CRITICAL "$IMAGE_NAME:$VERSION"
    fi
else
    log_error "Build failed"
    exit 1
fi
"""
        
        build_path = output_dir / "build.sh"
        with open(build_path, 'w') as f:
            f.write(build_script)
        os.chmod(build_path, 0o755)
        
        # Deploy script
        deploy_script = f"""#!/bin/bash
# Docker deployment script for {app_name}
# Generated by Infrastructure Management Subagent

set -euo pipefail

GREEN='\\033[0;32m'
YELLOW='\\033[1;33m'
NC='\\033[0m'

log_info() {{ echo -e "${{GREEN}}[INFO]${{NC}} $1"; }}
log_warn() {{ echo -e "${{YELLOW}}[WARN]${{NC}} $1"; }}

ENVIRONMENT="${{1:-development}}"

case "$ENVIRONMENT" in
    development|dev)
        log_info "Starting development environment..."
        docker-compose up -d
        ;;
    production|prod)
        log_info "Starting production environment..."
        docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
        ;;
    *)
        echo "Usage: $0 {{development|production}}"
        exit 1
        ;;
esac

log_info "Waiting for services to be healthy..."
sleep 10

docker-compose ps
log_info "Deployment completed"
"""
        
        deploy_path = output_dir / "deploy.sh"
        with open(deploy_path, 'w') as f:
            f.write(deploy_script)
        os.chmod(deploy_path, 0o755)
        
        # Security scan script
        security_script = f"""#!/bin/bash
# Security scanning script for {app_name}
# Generated by Infrastructure Management Subagent

set -euo pipefail

GREEN='\\033[0;32m'
RED='\\033[0;31m'
NC='\\033[0m'

log_info() {{ echo -e "${{GREEN}}[INFO]${{NC}} $1"; }}
log_error() {{ echo -e "${{RED}}[ERROR]${{NC}} $1"; }}

IMAGE_NAME="{config.get('IMAGE_NAME', app_name)}"
VERSION="${{1:-latest}}"

log_info "Running security scan on $IMAGE_NAME:$VERSION"

# Check if Trivy is installed
if ! command -v trivy &> /dev/null; then
    log_error "Trivy is not installed. Please install it first:"
    echo "curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin"
    exit 1
fi

# Run comprehensive security scan
log_info "Scanning for vulnerabilities..."
trivy image --format table --exit-code 1 --severity HIGH,CRITICAL "$IMAGE_NAME:$VERSION"

log_info "Scanning for misconfigurations..."
trivy config --format table .

log_info "Scanning filesystem..."
trivy fs --format table .

log_info "Security scan completed"
"""
        
        security_path = output_dir / "security-scan.sh"
        with open(security_path, 'w') as f:
            f.write(security_script)
        os.chmod(security_path, 0o755)


def main():
    """Command-line interface for Docker Configuration Generator."""
    
    parser = argparse.ArgumentParser(
        description='Generate production-ready Docker configurations',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate Dockerfile
  python3 generate-docker-configs.py dockerfile --config config.json

  # Generate complete Docker stack
  python3 generate-docker-configs.py stack --config config.json --output ./docker

  # Generate with inline configuration
  python3 generate-docker-configs.py dockerfile \\
    --set APP_NAME=my-app \\
    --set PACKAGE_MANAGER=npm \\
    --set PORT=3000
"""
    )
    
    parser.add_argument('type',
                       choices=['dockerfile', 'compose', 'dockerignore', 'stack'],
                       help='Type of Docker configuration to generate')
    
    parser.add_argument('--config', '-c',
                       help='JSON/YAML configuration file')
    
    parser.add_argument('--output', '-o',
                       help='Output file or directory')
    
    parser.add_argument('--set',
                       action='append',
                       help='Set configuration value (KEY=VALUE)')
    
    parser.add_argument('--template-dir',
                       help='Directory containing templates')
    
    parser.add_argument('--dry-run',
                       action='store_true',
                       help='Show what would be generated without creating files')
    
    args = parser.parse_args()
    
    # Initialize generator
    generator = DockerConfigGenerator(args.template_dir)
    
    # Load configuration
    config = {}
    
    if args.config:
        config_path = Path(args.config)
        if config_path.exists():
            with open(config_path, 'r') as f:
                if config_path.suffix.lower() in ['.yaml', '.yml']:
                    config = yaml.safe_load(f) or {}
                else:
                    config = json.load(f)
        else:
            print(f"Configuration file not found: {args.config}")
            sys.exit(1)
    
    # Apply command-line overrides
    if args.set:
        for setting in args.set:
            if '=' in setting:
                key, value = setting.split('=', 1)
                try:
                    config[key] = json.loads(value)
                except json.JSONDecodeError:
                    config[key] = value
            else:
                print(f"Invalid setting format: {setting} (use KEY=VALUE)")
                sys.exit(1)
    
    # Set default app name if not specified
    if not config.get('APP_NAME'):
        config['APP_NAME'] = 'my-app'
    
    try:
        if args.type == 'stack':
            # Generate complete Docker stack
            if args.dry_run:
                print("Dry-run mode: Would generate Docker stack with configuration:")
                print(json.dumps(config, indent=2))
            else:
                configs = generator.generate_container_configs(config, args.output)
                print(f"Generated {len(configs)} Docker configuration files")
        else:
            # Generate single configuration type
            output_file = args.output if not args.dry_run else None
            
            if args.type == 'dockerfile':
                result = generator.generate_dockerfile(config, output_file)
            elif args.type == 'compose':
                result = generator.generate_compose_file(config, output_file)
            elif args.type == 'dockerignore':
                result = generator.generate_dockerignore(config, output_file)
            
            if args.dry_run:
                print(f"Generated {args.type} content:")
                print("=" * 50)
                print(result)
            elif not args.output:
                print(result)
                
    except Exception as e:
        print(f"Error: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()